{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KeyWord_extraction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princetyagitech/NLP/blob/master/KeyWord_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cJE3AJlrtzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "83db4041-4477-4191-fa9c-89fc329b80a5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('wordnet') \n",
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayq61hEksHo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4a59094d-ac21-48b6-9557-4ca9e6cb0ec7"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntcfntlxsoZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/drive/My Drive/nips-papers.zip'\n",
        "path1='/content/drive/My Drive'\n",
        "import os\n",
        "#os.listdir(path)\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(path, 'r')\n",
        "zip_ref.extractall(path1)\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN0Ih1Goto84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "papers=pd.read_csv(path1+'/papers.csv')\n",
        "paper_authors=pd.read_csv(path1+'/paper_authors.csv')\n",
        "authors=pd.read_csv(path1+'/authors.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLijNYiBukOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=papers[papers['abstract']!='Abstract Missing'].reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8yDQKwRurP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e393a88-3a1f-472b-92da-f3f186e50de6"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJbjqZtFv80g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a3a45dce-2524-4141-b96f-32449f71623d"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>941</td>\n",
              "      <td>1861</td>\n",
              "      <td>2000</td>\n",
              "      <td>Algorithms for Non-negative Matrix Factorization</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1861-algorithms-for-non-negative-matrix-factor...</td>\n",
              "      <td>Non-negative matrix factorization (NMF) has pr...</td>\n",
              "      <td>Algorithms for Non-negative Matrix\\nFactorizat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1067</td>\n",
              "      <td>1975</td>\n",
              "      <td>2001</td>\n",
              "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1975-characterizing-neural-gain-control-using-...</td>\n",
              "      <td>Spike-triggered averaging techniques are effec...</td>\n",
              "      <td>Characterizing neural gain control using\\nspik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2384</td>\n",
              "      <td>3163</td>\n",
              "      <td>2007</td>\n",
              "      <td>Competition Adds Complexity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3163-competition-adds-complexity.pdf</td>\n",
              "      <td>It is known that determinining whether a DEC-P...</td>\n",
              "      <td>Competition adds complexity\\n\\nJudy Goldsmith\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2385</td>\n",
              "      <td>3164</td>\n",
              "      <td>2007</td>\n",
              "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3164-efficient-principled-learning-of-thin-jun...</td>\n",
              "      <td>We present the first truly polynomial algorith...</td>\n",
              "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2388</td>\n",
              "      <td>3167</td>\n",
              "      <td>2007</td>\n",
              "      <td>Regularized Boost for Semi-Supervised Learning</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3167-regularized-boost-for-semi-supervised-lea...</td>\n",
              "      <td>Semi-supervised inductive learning concerns ho...</td>\n",
              "      <td>Regularized Boost for Semi-Supervised Learning...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                         paper_text\n",
              "0    941  ...  Algorithms for Non-negative Matrix\\nFactorizat...\n",
              "1   1067  ...  Characterizing neural gain control using\\nspik...\n",
              "2   2384  ...  Competition adds complexity\\n\\nJudy Goldsmith\\...\n",
              "3   2385  ...  Efficient Principled Learning of Thin Junction...\n",
              "4   2388  ...  Regularized Boost for Semi-Supervised Learning...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQWTTDdGwXvO",
        "colab_type": "text"
      },
      "source": [
        "# Text Pre-Processing\n",
        "Main aim is to remove unwanted punctuations ,digits and convert words to stem words and normalizing the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPbA2oiFwrij",
        "colab_type": "text"
      },
      "source": [
        "### Finding out average length of every abstract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf9-zuiawUP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "f9a65033-dd4c-45a3-cbfa-0b89bd74cc73"
      },
      "source": [
        "dataset['wordcount']=dataset['abstract'].apply(lambda x: len(str(x).split(' ')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GuGpRBFxDqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7a987edf-6b79-4750-9aa6-b072ce318efb"
      },
      "source": [
        "dataset[['abstract','wordcount']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>wordcount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>Non-negative matrix factorization (NMF) has pr...</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>Spike-triggered averaging techniques are effec...</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2384</th>\n",
              "      <td>It is known that determinining whether a DEC-P...</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>We present the first truly polynomial algorith...</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2388</th>\n",
              "      <td>Semi-supervised inductive learning concerns ho...</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               abstract  wordcount\n",
              "941   Non-negative matrix factorization (NMF) has pr...        107\n",
              "1067  Spike-triggered averaging techniques are effec...         81\n",
              "2384  It is known that determinining whether a DEC-P...         67\n",
              "2385  We present the first truly polynomial algorith...        143\n",
              "2388  Semi-supervised inductive learning concerns ho...        119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxpRcYcTyxON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "19adc185-c235-4e7e-f243-c617a21c20d8"
      },
      "source": [
        "dataset.wordcount.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3924.000000\n",
              "mean      148.390928\n",
              "std        45.605755\n",
              "min        19.000000\n",
              "25%       116.000000\n",
              "50%       143.000000\n",
              "75%       177.000000\n",
              "max       317.000000\n",
              "Name: wordcount, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxa38H31y59C",
        "colab_type": "text"
      },
      "source": [
        "So average length of column is 148 and max is 317,min is 19."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRGJ4h7_zOdb",
        "colab_type": "text"
      },
      "source": [
        "### Most Common and Uncommon Words in corpus of text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ARr4df6y2Uu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "18175c36-515d-473e-f9b7-de9291a6386a"
      },
      "source": [
        "#Identify common words\n",
        "common = pd.Series(' '.join(dataset['abstract']).split()).value_counts()[:20]\n",
        "print(common)\n",
        "uncommon=pd.Series(' '.join(dataset['abstract']).split()).value_counts()[-20:]\n",
        "print(uncommon)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the         29793\n",
            "of          20918\n",
            "a           16339\n",
            "and         13626\n",
            "to          12869\n",
            "in           8980\n",
            "that         7838\n",
            "is           7666\n",
            "for          7169\n",
            "We           6238\n",
            "on           5579\n",
            "we           5167\n",
            "with         4512\n",
            "this         3677\n",
            "as           3643\n",
            "are          3529\n",
            "an           3366\n",
            "by           3197\n",
            "can          2953\n",
            "learning     2825\n",
            "dtype: int64\n",
            "gFIC.                 1\n",
            "m}$,                  1\n",
            "fixed-step-size       1\n",
            "grammars.             1\n",
            "(KMC),                1\n",
            "backlog               1\n",
            "$f(x_1(u),            1\n",
            "$|z                   1\n",
            "Context-Sensitive     1\n",
            "\\emph{new}            1\n",
            "multi-Gigabyte        1\n",
            "meaningful\"           1\n",
            "$\\Pi$                 1\n",
            "surged                1\n",
            "readers.              1\n",
            "learning-theoretic    1\n",
            "$i=1,2,\\ldots,m$,     1\n",
            "neglected             1\n",
            "Autism                1\n",
            "$\\ps$                 1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN7P38THz1a4",
        "colab_type": "text"
      },
      "source": [
        "Looks like most uncommon words are actually noise in the dataset which we need to remove."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goksVGQ00Ypq",
        "colab_type": "text"
      },
      "source": [
        "### Removing stopwords from the corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDF0F3XHzdYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0U8HMmO1DhZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8c0630bf-9e70-4a59-d2f0-8c298f4f66a9"
      },
      "source": [
        "dataset['abstract'][941]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Non-negative matrix factorization (NMF) has previously been shown to \\r\\nbe a useful decomposition for multivariate data. Two different multi- \\r\\nplicative algorithms for NMF are analyzed. They differ only slightly in \\r\\nthe multiplicative factor used in the update rules. One algorithm can be \\r\\nshown to minimize the conventional least squares error while the other \\r\\nminimizes the generalized Kullback-Leibler divergence. The monotonic \\r\\nconvergence of both algorithms can be proven using an auxiliary func- \\r\\ntion analogous to that used for proving convergence of the Expectation- \\r\\nMaximization algorithm. The algorithms can also be interpreted as diag- \\r\\nonally rescaled gradient descent, where the rescaling factor is optimally \\r\\nchosen to ensure convergence. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muO-aVQo0mq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus=[]\n",
        "for i in range(len(dataset)):\n",
        "  #Remove punctuations\n",
        "    text = re.sub('[^a-zA-Z]', ' ', dataset['abstract'][i])\n",
        "    \n",
        "    #Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    ##Convert to list from string\n",
        "    text = text.split()\n",
        "    \n",
        "    ##Stemming\n",
        "    ps=PorterStemmer()\n",
        "    #Lemmatisation\n",
        "    lem = WordNetLemmatizer()\n",
        "    text = [lem.lemmatize(word) for word in text if not word in  \n",
        "            stop_words] \n",
        "    text = \" \".join(text)\n",
        "    corpus.append(text)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS8NdNSk1ftv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3918ef6d-a33f-4f54-9e6a-340b66ba5df9"
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'non negative matrix factorization nmf useful decomposition multivariate data different multi plicative algorithm nmf analyzed differ slightly multiplicative factor used update rule algorithm minimize conventional least square error minimizes generalized kullback leibler divergence monotonic convergence algorithm proven auxiliary func tion analogous used proving convergence expectation maximization algorithm algorithm interpreted diag onally rescaled gradient descent rescaling factor optimally chosen ensure convergence'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aErRGzcZ1yYw",
        "colab_type": "text"
      },
      "source": [
        "# Creating a vector of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGnWgidE1yNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "cv=CountVectorizer(max_df=0.8,stop_words=stop_words, max_features=10000, ngram_range=(1,3))\n",
        "X=cv.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g61H6bk1wjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6d89512f-ce06-4bcb-efc9-8c2aa5888be1"
      },
      "source": [
        "list(cv.vocabulary_.keys())[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['non',\n",
              " 'negative',\n",
              " 'matrix',\n",
              " 'factorization',\n",
              " 'nmf',\n",
              " 'useful',\n",
              " 'decomposition',\n",
              " 'multivariate',\n",
              " 'data',\n",
              " 'different']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDmwaltF3ATp",
        "colab_type": "text"
      },
      "source": [
        "# TF-IDF Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5FZsIR43EZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for sorting tf_idf in descending order\n",
        "from scipy.sparse import coo_matrix\n",
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        " \n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "    \n",
        "    # word index and corresponding tf-idf score\n",
        "    for idx, score in sorted_items:\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        " \n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enZpHWt83gLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        " \n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(X)\n",
        "# get feature names\n",
        "feature_names=cv.get_feature_names()\n",
        "keywordslist=[]\n",
        "for i in range(len(corpus)):\n",
        "  keyl=[]\n",
        "  #generate tf-idf for the given document\n",
        "  tf_idf_vector=tfidf_transformer.transform(cv.transform([corpus[i]]))\n",
        "  #sort the tf-idf vectors by descending order of scores\n",
        "  sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "  #extract only the top n; n here is 10\n",
        "  keywords=extract_topn_from_vector(feature_names,sorted_items,5)\n",
        "  keyl=keywords\n",
        "  keywordslist.append(keyl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8fB7xmU4OaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "8c347dfe-5fa3-48cc-f296-6a2fb2b7a0a6"
      },
      "source": [
        "keywordslist[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'algorithm': 0.18,\n",
              "  'algorithm minimize': 0.156,\n",
              "  'convergence': 0.208,\n",
              "  'factor': 0.162,\n",
              "  'nmf': 0.288},\n",
              " {'gain': 0.2,\n",
              "  'gain control': 0.313,\n",
              "  'spike': 0.195,\n",
              "  'spike triggered': 0.294,\n",
              "  'triggered': 0.278},\n",
              " {'complete': 0.27,\n",
              "  'cooperative': 0.347,\n",
              "  'expected reward': 0.37,\n",
              "  'reward': 0.24,\n",
              "  'whether': 0.26},\n",
              " {'junction': 0.238,\n",
              "  'junction tree': 0.249,\n",
              "  'mutual information': 0.18,\n",
              "  'polynomial': 0.209,\n",
              "  'treewidth': 0.327},\n",
              " {'boosting algorithm': 0.281,\n",
              "  'local smoothness': 0.348,\n",
              "  'regularizer': 0.323,\n",
              "  'semi': 0.259,\n",
              "  'semi supervised': 0.283}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPXkDG8t4f7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}